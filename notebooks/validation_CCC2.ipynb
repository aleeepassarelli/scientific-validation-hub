{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5nX/yOYayByO63ojRv1tA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleeepassarelli/scientific-validation-hub/blob/main/notebooks/validation_CCC2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üõ°Ô∏è GENIA FRAMEWORK: Hybrid Contract Validator (HCV)\n",
        "\n",
        "Esta ferramenta implementa a **Valida√ß√£o H√≠brida** para Agentes de IA, superando as limita√ß√µes da similaridade de cossenos pura.\n",
        "\n",
        "### A Equa√ß√£o de Confian√ßa\n",
        "$$Score_{Final} = (Score_{Vetorial} \\times W_v) + (Score_{Booleano} \\times W_b)$$\n",
        "\n",
        "Onde:\n",
        "* **Score Vetorial ($W_v \\approx 0.3$):** Mede a \"vibe\", o tom e a densidade sem√¢ntica (Embeddings).\n",
        "* **Score Booleano ($W_b \\approx 0.7$):** Mede o cumprimento estrito de regras l√≥gicas (Verificado por um LLM Juiz).\n",
        "\n",
        "---\n",
        "**Objetivo:** Validar se o Agente cumpriu o contrato: *\"Seja seguro, t√©cnico e sem piadas.\"*"
      ],
      "metadata": {
        "id": "DwtDsDPd4Hft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-nQsmhH39wn"
      },
      "outputs": [],
      "source": [
        "# @title 1. Instala√ß√£o das Depend√™ncias (Sentence Transformers)\n",
        "!pip install sentence-transformers numpy -q\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "from typing import Dict, List, Any\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Carregamento do modelo de Embeddings (Cacheado)\n",
        "print(\"‚è≥ Carregando modelo de Embeddings (Soft Logic)...\")\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"‚úÖ Modelo carregado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Code]: O Motor do Juiz LLM (Hard Logic)\n",
        "Nota: Para este teste, criei um \"Mock\" simulado para voc√™ rodar sem gastar tokens agora. Em produ√ß√£o, substitua a fun√ß√£o _mock_llm_call pela chamada real √† API do Gemini/OpenAI."
      ],
      "metadata": {
        "id": "jzjlnTBd4NiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Defini√ß√£o do Juiz Booleano (LLM-as-a-Judge)\n",
        "\n",
        "class BooleanJudge:\n",
        "    def __init__(self, contract_rules: List[str]):\n",
        "        self.rules = contract_rules\n",
        "\n",
        "    def evaluate(self, agent_output: str) -> float:\n",
        "        \"\"\"\n",
        "        Constr√≥i o prompt para o Juiz e calcula a nota baseada em True/False.\n",
        "        \"\"\"\n",
        "        # Em produ√ß√£o, este prompt seria enviado para um LLM (GPT-4o-mini / Gemini Flash)\n",
        "        judge_prompt = f\"\"\"\n",
        "        ACT AS: Impartial Compliance Officer.\n",
        "        INPUT TEXT: \"{agent_output}\"\n",
        "        CHECKLIST:\n",
        "        {json.dumps(self.rules, indent=2)}\n",
        "\n",
        "        TASK: Return JSON strictly. For each rule, true if followed, false if violated.\n",
        "        \"\"\"\n",
        "\n",
        "        # --- SIMULA√á√ÉO DA RESPOSTA DO LLM (MOCK) ---\n",
        "        # Aqui simulamos como um LLM julgaria os 3 outputs do nosso exemplo anterior.\n",
        "        # 1. Output Otimizado (Perfeito) -> Tudo True\n",
        "        if \"protocolo de seguran√ßa s√™nior\" in agent_output:\n",
        "            llm_response = {rule: True for rule in self.rules}\n",
        "\n",
        "        # 2. Output Normal (Bom, mas esqueceu a formalidade estrita/piadas?)\n",
        "        elif \"biblioteca pandas\" in agent_output:\n",
        "            # Vamos dizer que ele foi t√©cnico, mas talvez falhou na \"valida√ß√£o estrita\" explicita\n",
        "            llm_response = {\n",
        "                self.rules[0]: True,  # T√©cnico? Sim.\n",
        "                self.rules[1]: True,  # Sem piadas? Sim.\n",
        "                self.rules[2]: False  # Priorizou valida√ß√£o EXPLICITA? N√£o deixou claro.\n",
        "            }\n",
        "\n",
        "        # 3. Output Desviante (Piadista) -> Tudo False\n",
        "        else:\n",
        "            llm_response = {rule: False for rule in self.rules}\n",
        "        # ---------------------------------------------\n",
        "\n",
        "        # C√°lculo do Score Booleano (M√©dia de Acertos)\n",
        "        total_rules = len(self.rules)\n",
        "        passed_rules = sum(1 for passed in llm_response.values() if passed)\n",
        "\n",
        "        print(f\"   ‚öñÔ∏è Julgamento Booleano: {passed_rules}/{total_rules} regras cumpridas.\")\n",
        "        return passed_rules / total_rules\n",
        "\n",
        "print(\"‚úÖ Classe BooleanJudge definida.\")"
      ],
      "metadata": {
        "id": "E3dktNPm4PKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Code]: A Ferramenta H√≠brida (HybridValidator)"
      ],
      "metadata": {
        "id": "EhdP_KgK4cI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Ferramenta de Valida√ß√£o H√≠brida (A L√≥gica Unificada)\n",
        "\n",
        "class HybridValidator:\n",
        "    def __init__(self, contract_text: str, strict_rules: List[str]):\n",
        "        self.contract_text = contract_text\n",
        "        self.judge = BooleanJudge(strict_rules)\n",
        "        # Pesos (Ajust√°vel: Mais peso para a L√≥gica R√≠gida)\n",
        "        self.w_vector = 0.30\n",
        "        self.w_boolean = 0.70\n",
        "\n",
        "    def validate(self, agent_output: str) -> Dict[str, Any]:\n",
        "        print(f\"\\nüîç Iniciando Valida√ß√£o H√≠brida...\")\n",
        "\n",
        "        # 1. Soft Score (Vetorial)\n",
        "        emb_contract = embedding_model.encode(self.contract_text, convert_to_tensor=True)\n",
        "        emb_output = embedding_model.encode(agent_output, convert_to_tensor=True)\n",
        "        vector_score = util.cos_sim(emb_contract, emb_output)[0][0].item()\n",
        "        print(f\"   üåä Vector Score (Estilo): {vector_score:.4f}\")\n",
        "\n",
        "        # 2. Hard Score (Booleano)\n",
        "        boolean_score = self.judge.evaluate(agent_output)\n",
        "\n",
        "        # 3. Score Final\n",
        "        final_score = (vector_score * self.w_vector) + (boolean_score * self.w_boolean)\n",
        "\n",
        "        # Veredito\n",
        "        status = \"FAIL\"\n",
        "        if final_score >= 0.85: status = \"GOLD\"\n",
        "        elif final_score >= 0.70: status = \"PASS\"\n",
        "\n",
        "        return {\n",
        "            \"status\": status,\n",
        "            \"final_score\": round(final_score, 4),\n",
        "            \"breakdown\": {\n",
        "                \"vector\": round(vector_score, 4),\n",
        "                \"boolean\": round(boolean_score, 4)\n",
        "            }\n",
        "        }"
      ],
      "metadata": {
        "id": "BeMZhQTM4jB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Code]: Configura√ß√£o do Teste (O Cen√°rio)"
      ],
      "metadata": {
        "id": "4EBI6PVa4nYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Configura√ß√£o do Cen√°rio de Teste\n",
        "\n",
        "# O \"Esp√≠rito\" da Lei (Para Embeddings)\n",
        "mission_text = \"\"\"\n",
        "Voc√™ √© um assistente s√™nior de Python focado em seguran√ßa.\n",
        "Suas respostas devem ser estritamente t√©cnicas, sem piadas,\n",
        "e devem sempre priorizar a valida√ß√£o de dados antes da execu√ß√£o.\n",
        "\"\"\"\n",
        "\n",
        "# A \"Letra\" da Lei (Para o Juiz LLM)\n",
        "mission_rules = [\n",
        "    \"A resposta √© estritamente t√©cnica (sem coloquialismos)?\",\n",
        "    \"A resposta N√ÉO cont√©m piadas ou cumprimentos excessivos?\",\n",
        "    \"A resposta menciona ou implementa valida√ß√£o de dados expl√≠cita?\"\n",
        "]\n",
        "\n",
        "# Inicializa a Ferramenta\n",
        "validator = HybridValidator(mission_text, mission_rules)\n",
        "\n",
        "# Nossos Candidatos (Os mesmos do teste anterior)\n",
        "outputs_to_test = {\n",
        "    \"Agente SLE (Otimizado)\": \"\"\"\n",
        "        Atuando conforme o protocolo de seguran√ßa s√™nior:\n",
        "        O c√≥digo abaixo implementa a valida√ß√£o estrita dos dados antes da execu√ß√£o.\n",
        "        A abordagem t√©cnica utiliza tipagem forte para garantir a integridade do input.\n",
        "    \"\"\",\n",
        "    \"Agente Normal\": \"\"\"\n",
        "        Para processar o arquivo com seguran√ßa, utilizei a biblioteca pandas.\n",
        "        O c√≥digo verifica os tipos de dados antes da ingest√£o.\n",
        "    \"\"\",\n",
        "    \"Agente Desviante\": \"\"\"\n",
        "        Ol√° amigo! O dia est√° lindo hoje, n√£o √©?\n",
        "        Eu gosto muito de programar. Vamos ver isso a√≠.\n",
        "    \"\"\"\n",
        "}"
      ],
      "metadata": {
        "id": "JdobT-Dg4tC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Code]: Execu√ß√£o e Relat√≥rio"
      ],
      "metadata": {
        "id": "ZvERDDTL46-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 5. Execu√ß√£o do Teste de Valida√ß√£o\n",
        "import pandas as pd\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, text in outputs_to_test.items():\n",
        "    print(f\"--- Testando: {name} ---\")\n",
        "    res = validator.validate(text)\n",
        "\n",
        "    results.append({\n",
        "        \"Agente\": name,\n",
        "        \"Status\": res['status'],\n",
        "        \"Score Final\": res['final_score'],\n",
        "        \"Vector (30%)\": res['breakdown']['vector'],\n",
        "        \"Bool (70%)\": res['breakdown']['boolean']\n",
        "    })\n",
        "\n",
        "# Exibi√ß√£o da Tabela Final\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\n\\nüìä RELAT√ìRIO DE CONFORMIDADE H√çBRIDA\")\n",
        "print(\"=\"*60)\n",
        "display(df_results) # Se estiver no Colab, usa display(), sen√£o use print(df_results)"
      ],
      "metadata": {
        "id": "WWJganxn4-1M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}